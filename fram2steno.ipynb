{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# General purpose\n",
    "import copy \n",
    "import pickle\n",
    "import warnings \n",
    "\n",
    "# Imputation and Data balancing \n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Machine Learning development \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# In-house libraries\n",
    "# Data preparation\n",
    "from Framingham_utils import *\n",
    "from Steno_utils import *\n",
    "\n",
    "# EDA\n",
    "from exploratory_data_analysis import * \n",
    "\n",
    "# Macine Learning development\n",
    "from train_utils import *\n",
    "from model_evaluation import *\n",
    "\n",
    "# Performance profiling \n",
    "from profiling import *\n",
    "\n",
    "# Directories, filenames, etc\n",
    "from constants import * \n",
    "\n",
    "# Filter warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Path to store obtained reusults\n",
    "STORE_PATH = r\".\\DSD2023_fram2steno_results\"\n",
    "\n",
    "# Save current working directory to come back later \n",
    "wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation \n",
    "fram_data, fram_X, fram_Y, fram_feat_names, fram_y_tag = prepare_Framingham(dataset_path = FRAM_PATH, filename = fram_filename)\n",
    "steno_data, steno_X, steno_Y, steno_feat_names, steno_y_tag = prepare_Steno(dataset_path = STENO_PATH, filename1 = steno_filename1, filename2 = steno_filename2)\n",
    "\n",
    "# Go back to previous directory \n",
    "os.chdir(wd)\n",
    "\n",
    "# Data partition - Train (80%) + Validation (20%)\n",
    "fram_X_train, fram_X_val, fram_y_train, fram_y_val, fram_train_data, fram_validation_data = train_test_split_and_concat(fram_X, fram_Y, test_size=0.2, random_state=4)\n",
    "steno_X_train, steno_X_val, steno_y_train, steno_y_val, steno_train_data, steno_validation_data = train_test_split_and_concat(steno_X, steno_Y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the common features in Frammingham and Steno \n",
    "fram_2common_X_train = fram_X_train[['male','age','currentSmoker','prevalentStroke','sysBP']]\n",
    "fram_2common_X_val = fram_X_val[['male','age','currentSmoker','prevalentStroke','sysBP']]\n",
    "\n",
    "steno_2common_X_train = steno_X_train[['sex','age','smoking','prevcvd','sbp']]\n",
    "steno_2common_X_val = steno_X_val[['sex','age','smoking','prevcvd','sbp']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN-Imputation (training and validation set separately)\n",
    "# Only for Framingham dataset\n",
    "# Imputer declaration \n",
    "imputer = KNNImputer(missing_values = np.nan , n_neighbors = 5, weights = 'uniform', metric = 'nan_euclidean',\n",
    "                      copy = 'false') \n",
    "\n",
    "# Imputation (training and validation separately)\n",
    "fram_train_data = imputer.fit_transform(fram_train_data)\n",
    "fram_validation_data = imputer.fit_transform(fram_validation_data) \n",
    "\n",
    "# Conversion from np.array to pd.DataFrame and convert from float to original datatype\n",
    "fram_train_data, fram_X_train, fram_y_train = numerical_conversion_Framingham(fram_train_data, fram_feat_names, fram_y_tag)\n",
    "fram_validation_data, fram_X_val, fram_y_val = numerical_conversion_Framingham(fram_validation_data, fram_feat_names, fram_y_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance dataset (only Frammingham)\n",
    "# Balancing with ADASYN\n",
    "fram_X_train, fram_y_train = ADASYN(sampling_strategy = 'minority',\n",
    "                                                random_state = 5,\n",
    "                                                n_neighbors = 5,\n",
    "                                                n_jobs = None).fit_resample(fram_X_train, fram_y_train) \n",
    "\n",
    "# Add column Y to dataframe \n",
    "fram_X_train.reset_index(drop=True, inplace=True)\n",
    "fram_y_train.reset_index(drop=True, inplace=True)\n",
    "fram_train_data = pd.concat([fram_X_train, fram_y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert steno y from series to dataframe \n",
    "steno_y_train = pd.DataFrame(steno_y_train)\n",
    "steno_y_train.columns = [steno_y_tag]\n",
    "\n",
    "steno_y_val = pd.DataFrame(steno_y_val)\n",
    "steno_y_val.columns = [steno_y_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract common features to train ML models with 2 data subsets with just the common features\n",
    "fram_2common_X_train = fram_X_train[['male','age','currentSmoker','prevalentStroke','sysBP']]\n",
    "fram_2common_X_val = fram_X_val[['male','age','currentSmoker','prevalentStroke','sysBP']]\n",
    "\n",
    "steno_2common_X_train = steno_X_train[['sex','age','smoking','prevcvd','sbp']]\n",
    "steno_2common_X_val = steno_X_val[['sex','age','smoking','prevcvd','sbp']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To rename variables names and format to be the same, so the second dataset can be used to train the same model\n",
    "fram_2common_X_train.rename(columns={'male':'sex', 'currentSmoker':'smoking','prevalentStroke':'prevcvd','sysBP':'sbp'}, inplace = True)\n",
    "fram_2common_X_val.rename(columns={'male':'sex', 'currentSmoker':'smoking','prevalentStroke':'prevcvd','sysBP':'sbp'}, inplace = True)\n",
    "# NOTE: sex = 1 is male, sex = 0 is female, so no transformation is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to \"EDA\" directory, if not create one \n",
    "if not os.path.exists('EDA'):\n",
    "    os.makedirs('EDA')\n",
    "\n",
    "# Change directory to \"EDA\"\n",
    "os.chdir('EDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to \"compared_distributions\" directory, if not create one\n",
    "if not os.path.exists('compared_distributions'):\n",
    "    os.makedirs('compared_distributions')\n",
    "\n",
    "# Change directory to \"compared_distributions\"\n",
    "os.chdir('compared_distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution comparison of Steno and Frammingham datasets in the common features \n",
    "\n",
    "# Dummy counter \n",
    "i = -1\n",
    "\n",
    "# List of ranges to plot the histograms\n",
    "ranges = [(0,1),(0,100),(0,1),(0,1),(50,300)]\n",
    "\n",
    "for feat in steno_2common_X_train:\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "    # Set IEEE style\n",
    "    plt.style.use(['science','ieee'])\n",
    "\n",
    "    # Figure\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "    \n",
    "    # Set figure title\n",
    "    fig.suptitle(feat)\n",
    "\n",
    "    ax[0].hist(steno_2common_X_train[feat], range = ranges[i], alpha=0.5, ec='g', label=\"\", fill=True)\n",
    "    ax[0].set_title('Steno')\n",
    "    ax[1].hist(fram_2common_X_train[feat], range = ranges[i],  alpha=0.5, ec='g', label=\"\", fill=True)\n",
    "    ax[1].set_title('Framingham')\n",
    "\n",
    "    # Save figure with high resolution \n",
    "    fig.savefig(feat + '_compared.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ('Frammingham 5 commons', 'Steno 5 commons')\n",
    "classifiers = {'SVM' : {}, 'MLP' : {}}\n",
    "regressors = {'SVM' : {}, 'MLP': {}}\n",
    "class_metrics = {'f1' : np.zeros(1), 'roc' : np.zeros(1), 'auc' : np.zeros(1), 'prob':  np.zeros(1)}\n",
    "reg_metrics = {'mae' : np.zeros(1), 'mse' : np.zeros(1), 'R1' : np.zeros(1)}\n",
    "\n",
    "# Generate dict to store results \n",
    "metrics_dict =  get_eval_dictionaries(datasets, classifiers, regressors, class_metrics, reg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare common numerical features to leave binary variables as they are \n",
    "common_numerical_features = ['age', 'sbp']\n",
    "\n",
    "# Cross standardization (i.e., Steno dataset will be normalized according to Framingam's mean and std)\n",
    "steno_2common_train_data, steno_2common_X_train, steno_2common_y_train = cross_standardization(fram_2common_X_train, steno_2common_X_train, steno_y_train, common_numerical_features)\n",
    "\n",
    "# Validation \n",
    "steno_2common_validation_data, steno_2common_X_val, steno_2common_y_val = cross_standardization(fram_2common_X_train, steno_2common_X_val, steno_y_val, common_numerical_features)\n",
    "fram_2common_validation_data, fram_2common_X_val, fram_2common_y_val = cross_standardization(fram_2common_X_train, fram_2common_X_val, fram_y_val, common_numerical_features)\n",
    "\n",
    "# The reference is standardized the last, to properly standardize the rest \n",
    "fram_2common_train_data, fram_2common_X_train, fram_2common_y_train = standardization(fram_2common_X_train, fram_y_train, common_numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to \"overlapped_distributions\" directory, if not create one\n",
    "if not os.path.exists('overlapped_distributions'):\n",
    "    os.makedirs('overlapped_distributions')\n",
    "\n",
    "# Change directory to \"compared_distributions\"\n",
    "os.chdir('overlapped_distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution comparison of Steno and Frammingham training datasets in the common features after standardization based on Framingham database\n",
    "for feat in steno_2common_X_train:\n",
    "    \n",
    "    # Figure\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "    # Set IEEE style\n",
    "    plt.style.use(['science','ieee'])\n",
    "    \n",
    "    # Set figure title\n",
    "    fig.suptitle(feat)\n",
    "\n",
    "    ax.hist(steno_2common_X_train[feat], alpha=0.5, color = 'b', label=\"\", fill=True)\n",
    "    #ax[0].set_title('Steno')\n",
    "    ax.hist(fram_2common_X_train[feat],  alpha=0.5, color = 'k', label=\"\", fill=True)\n",
    "    #ax[1].set_title('Framingham')\n",
    "\n",
    "    # Set the legend only in the first figure\n",
    "    if feat == 'sex':\n",
    "        ax.legend([\"Steno\", \"Frammingham\"],loc='upper right')\n",
    "    \n",
    "    # Save figure with high resolution \n",
    "    fig.savefig(feat + '_train_norm_overlapped.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution comparison of Steno and Frammingham validation datasets in the common features after standardization based on Framingham database\n",
    "for feat in steno_2common_X_val:\n",
    "    \n",
    "    # Figure\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "    # Set IEEE style\n",
    "    plt.style.use(['science','ieee'])\n",
    "\n",
    "    # Set figure title\n",
    "    fig.suptitle(feat)\n",
    "\n",
    "    ax.hist(steno_2common_X_val[feat], alpha=0.5, color = 'b', label=\"\", fill=True)\n",
    "    #ax[0].set_title('Steno')\n",
    "    ax.hist(fram_2common_X_val[feat],  alpha=0.5, color = 'k', label=\"\", fill=True)\n",
    "    #ax[1].set_title('Framingham')\n",
    "\n",
    "    # Set the legend only in the first figure\n",
    "    if feat == 'sex':\n",
    "        ax.legend([\"Steno\", \"Frammingham\"],loc='upper right')\n",
    "    \n",
    "    # Save figure with high resolution \n",
    "    fig.savefig(feat + '_val_norm_overlapped.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns to Steno target variable to perform the classification experiment.\n",
    "\n",
    "# It is 1 if cvd_risk_10y >= 0.2 and 0 otherwise (according to already established criteria https://steno.shinyapps.io/T1RiskEngine/)\n",
    "steno_threshold_binary  = 0.2 \n",
    "\n",
    "# Training set \n",
    "# Creation of dummy deep copies, otherwise both columns of dataframe are modified \n",
    "a = copy.deepcopy(steno_y_train)\n",
    "b = copy.deepcopy(steno_y_train)\n",
    "\n",
    "# Binary classification: add the classification value and assign correspondant value\n",
    "steno_y_train.insert(1, \"Class_label_binary\", a, allow_duplicates=False)\n",
    "steno_y_train.loc[steno_y_train.cvd_risk_10y >= steno_threshold_binary, \"Class_label_binary\"] = 1\n",
    "steno_y_train.loc[steno_y_train.cvd_risk_10y < steno_threshold_binary, \"Class_label_binary\"] = 0\n",
    "\n",
    "# Validation set \n",
    "# Creation of dummy deep copies, otherwise both columns of dataframe are modified \n",
    "a = copy.deepcopy(steno_y_val)\n",
    "b = copy.deepcopy(steno_y_val)\n",
    "\n",
    "# Binary classification: add the classification value and assign correspondant value\n",
    "steno_y_val.insert(1, \"Class_label_binary\", a, allow_duplicates=False)\n",
    "steno_y_val.loc[steno_y_val.cvd_risk_10y >= steno_threshold_binary, \"Class_label_binary\"] = 1\n",
    "steno_y_val.loc[steno_y_val.cvd_risk_10y < steno_threshold_binary, \"Class_label_binary\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train \n",
    "print(\"Binary classification - Steno Number of '1' after the conversion setting the threshold to %f: %i\\t \" % (steno_threshold_binary, steno_y_train.Class_label_binary.value_counts()[1]))\n",
    "print(\"Binary classification - Steno Number of '0' after the conversion setting the threshold to %f: %i\\t \" % (steno_threshold_binary, steno_y_train.Class_label_binary.value_counts()[0]))\n",
    "\n",
    "print(\"Binary classification - Steno Number of '1' after the conversion setting the threshold to %f: %i\\t\" % (steno_threshold_binary, steno_y_val.Class_label_binary.value_counts()[1])) \n",
    "print(\"Binary classification - Steno Number of '0' after the conversion setting the threshold to %f: %i\\t\" % (steno_threshold_binary, steno_y_val.Class_label_binary.value_counts()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates and/or goes to the path to store the results \n",
    "if not os.path.exists(STORE_PATH):\n",
    "    os.mkdir(STORE_PATH)\n",
    "os.chdir(STORE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification models \n",
    "# SVM \n",
    "svm_base = SGDClassifier(loss='hinge', penalty = 'l2', alpha = 0.01, learning_rate = 'constant', eta0 = 1, warm_start = False, random_state = 12345)\n",
    "\n",
    "# MLP \n",
    "perceptron_base = SGDClassifier(loss='perceptron', random_state = 12345, warm_start = False, early_stopping=False, # Early Stopping set to false to partial_fit\n",
    "            learning_rate = 'constant', eta0 = 0.01, max_iter = 100, shuffle=False)\n",
    "\n",
    "# Hyperparameters \n",
    "svm_params = {\n",
    "            'alpha': [0.00001, 0.0001, 0.5, 1],\n",
    "            \"learning_rate\" : ['constant', 'adaptive'],\n",
    "            \"eta0\" : [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "              }\n",
    "\n",
    "\n",
    "perc_params = {\"tol\" : [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "            \"learning_rate\" : ['constant', 'adaptive'],\n",
    "             \"eta0\" : [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "             \"power_t\" : [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Training phase: find the optimal hyperparameters for this models trained with Framingham datasets\n",
    "SVM_model_steno, SVM_train_results_steno, SVM_cv_results_steno, SVM_best_params  = train_classifier(svm_base, svm_params, \"SVM\", \"Steno Classification (5 common)\", fram_2common_X_train.to_numpy(), np.ravel(fram_y_train['TenYearCHD']), cv = 10, scoring = 'roc_auc')\n",
    "perc_model_steno, perc_train_results_steno, perc_cv_results_steno, perc_best_params  = train_classifier(perceptron_base, perc_params, \"Perceptron\", \"Steno Classification (5 common)\", fram_2common_X_train.to_numpy(), np.ravel(fram_y_train['TenYearCHD']), cv = 10, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models with the best parameters to be trained with both datasets \n",
    "svm_prev = SGDClassifier(loss='hinge', penalty = 'l2' , warm_start = False, random_state = 12345, **SVM_best_params) # Early Stopping set to false to partial_fit\n",
    "perceptron_prev = SGDClassifier(loss='perceptron', random_state = 12345, warm_start = False, early_stopping=False, \n",
    "            max_iter = 100, **perc_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters are not stored properly. This is done manually (after the execution of the previous cell)\n",
    "svm_prev = SGDClassifier(loss='hinge', penalty = 'l2' , warm_start = False, random_state = 12345,\n",
    "                        alpha= 0.5,\n",
    "                        eta0= 0.001,\n",
    "                        learning_rate= 'constant') # Early Stopping set to false to partial_fit\n",
    "perceptron_prev = SGDClassifier(loss='perceptron', random_state = 12345, warm_start = False, early_stopping=False, max_iter = 100,\n",
    "                        eta0 = 1.0,\n",
    "                        learning_rate =  'constant',\n",
    "                        power_t =  0.5,\n",
    "                        tol =  0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial fit just iterate once through the training set, so 10 times with Cross Validation are performed\n",
    "# Frammingham iterations \n",
    "fram_iterations = 10\n",
    "\n",
    "# Framingham repetitions\n",
    "fram_repetitions = 1\n",
    "\n",
    "# Declare a StratifiedKFold object with 10 folds\n",
    "skf = StratifiedKFold(n_splits = fram_iterations, shuffle = True, random_state = 12345)\n",
    "\n",
    "# For simplicity of code\n",
    "X = fram_2common_X_train.to_numpy()\n",
    "y = np.ravel(fram_y_train['TenYearCHD'])\n",
    "\n",
    "# Current model \n",
    "curr_perc_model = perceptron_prev\n",
    "curr_svm_model = svm_prev\n",
    "\n",
    "# Empty list to store the results of the 10 iterations\n",
    "fram_perc_train_results = []\n",
    "fram_svm_train_results = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "    # Print number of iteration out of total \n",
    "    print(\"Iteration %i of %i...\" % (i, fram_iterations*fram_repetitions))\n",
    "\n",
    "    # Extract the training and test set for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the model for this fold\n",
    "    perc_pretrained = curr_perc_model.partial_fit(X_train, y_train, classes=np.unique(steno_y_train['Class_label_binary']))\n",
    "    svm_pretrained = curr_svm_model.partial_fit(X_train, y_train, classes=np.unique(steno_y_train['Class_label_binary']))\n",
    "\n",
    "    # Predict the test set\n",
    "    y_perc_pred = perc_pretrained.predict(X_test)\n",
    "    y_svm_pred = svm_pretrained.predict(X_test)\n",
    "\n",
    "    # Test the model for this fold \n",
    "    perc_auc = metrics.roc_auc_score(y_test, y_perc_pred)\n",
    "    svm_auc = metrics.roc_auc_score(y_test, y_svm_pred)\n",
    "\n",
    "    # Append the results to the list\n",
    "    fram_perc_train_results.append(y_perc_pred)\n",
    "    fram_svm_train_results.append(y_svm_pred)\n",
    "    \n",
    "    # Update current model \n",
    "    curr_perc_model = perc_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation before incremental training (SVM)\n",
    "steno_acc_SVM_prev, steno_auc_SVM_prev, f1_steno_SVM_prev, recall_steno_SVM_prev, prec_steno_SVM_prev= perc_clas_eval(svm_pretrained, steno_2common_X_val.to_numpy(), steno_y_val['Class_label_binary'])\n",
    "print(\"SVM - Steno Only 5 common -> ACC: %f || AUC: %f || F1-score: %f || Recall: %f || Precision: %f\" % (steno_acc_SVM_prev, steno_auc_SVM_prev, f1_steno_SVM_prev, recall_steno_SVM_prev, prec_steno_SVM_prev))\n",
    "fram_acc_SVM_prev, fram_auc_SVM_prev, f1_fram_SVM_prev, recall_fram_SVM_prev, prec_fram_SVM_prev = perc_clas_eval(svm_pretrained, fram_2common_X_val.to_numpy(), fram_y_val['TenYearCHD'])\n",
    "print(\"SVM - Frammingham Only 5 common -> ACC: %f || AUC: %f || F1-score: %f || Recall: %f || Precision: %f\" % (fram_acc_SVM_prev, fram_auc_SVM_prev, f1_fram_SVM_prev, recall_fram_SVM_prev, prec_fram_SVM_prev))\n",
    "\n",
    "# Save results in an Excel file \n",
    "results = pd.DataFrame({'ACC': [steno_acc_SVM_prev, fram_acc_SVM_prev], 'AUC': [steno_auc_SVM_prev, fram_auc_SVM_prev], 'F1-score': [f1_steno_SVM_prev, f1_fram_SVM_prev], 'Recall': [recall_steno_SVM_prev, recall_fram_SVM_prev], 'Precision': [prec_steno_SVM_prev, prec_fram_SVM_prev]}, index = ['Steno Only 5 common', 'Frammingham Only 5 common'])\n",
    "results.to_excel(\"SVM_pre-training_Steno_and_Frammingham_5_common.xlsx\")\n",
    "\n",
    "# Model validation before incremental training (Perceptron)\n",
    "steno_acc_perc_prev, steno_auc_perc_prev, f1_steno_perc_prev, recall_steno_perc_prev, prec_steno_perc_prev = perc_clas_eval(perc_pretrained, steno_2common_X_val.to_numpy(), steno_y_val['Class_label_binary'])\n",
    "print(\"Perceptron before Incr. training - Steno Only 5 common -> ACC: %f || AUC: %f || F1-score: %f || Recall: %f || Precision: %f\" % (steno_acc_perc_prev, steno_auc_perc_prev, f1_steno_perc_prev,  recall_steno_perc_prev, prec_steno_perc_prev))\n",
    "fram_acc_perc_prev, fram_auc_perc_prev, f1_fram_perc_prev, recall_fram_perc_prev, prec_fram_perc_prev = perc_clas_eval(perc_pretrained, fram_2common_X_val.to_numpy(), fram_y_val['TenYearCHD'])\n",
    "print(\"Perceptron before Incr. training - Frammingham Only 5 common -> ACC: %f || AUC: %f || F1-score: %f || Recall: %f || Precision: %f\" % (fram_acc_perc_prev, fram_auc_perc_prev, f1_fram_perc_prev, recall_fram_perc_prev, prec_fram_perc_prev))\n",
    "\n",
    "# Save results in an Excel file\n",
    "results = pd.DataFrame({'ACC': [steno_acc_perc_prev, fram_acc_perc_prev], 'AUC': [steno_auc_perc_prev, fram_auc_perc_prev], 'F1-score': [f1_steno_perc_prev, f1_fram_perc_prev], 'Recall': [recall_steno_perc_prev, recall_fram_perc_prev], 'Precision': [prec_steno_perc_prev, prec_fram_perc_prev]}, index = ['Steno Only 5 common', 'Frammingham Only 5 common'])\n",
    "results.to_excel(\"Perceptron_pre-training_Steno_and_Frammingham_5_common.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix in the pre-training\n",
    "title = \"Steno Classification Approach (Steno pre-training) - SVM \"\n",
    "disp = plot_confusion_matrix(svm_pretrained, steno_2common_X_val, steno_y_val['Class_label_binary'],\n",
    "                        cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "# Save figure \n",
    "plt.savefig(\"Steno_SVM_confusion_matrix_pre-training.png\", dpi = 300)\n",
    "\n",
    "title = \"Frammingham Classification Approach (Steno pre-training) - SVM\"\n",
    "disp = plot_confusion_matrix(svm_pretrained, fram_2common_X_val.to_numpy(), fram_y_val['TenYearCHD'], \n",
    "                        cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "# Save figure\n",
    "plt.savefig(\"Frammingham_SVM_confusion_matrix_pre-training.png\", dpi = 300)\n",
    "\n",
    "# Confusion matrix for Frammingham \n",
    "title = \"Steno Classification Approach (Steno pre-training) - Perceptron\"\n",
    "disp = plot_confusion_matrix(perc_pretrained, steno_2common_X_val, steno_y_val['Class_label_binary'],\n",
    "                        cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "# Save figure\n",
    "plt.savefig(\"Steno_Perceptron_confusion_matrix_pre-training.png\", dpi = 300)\n",
    "\n",
    "title = \"Frammingham Classification Approach (Steno pre-training) - Perceptron\"\n",
    "disp = plot_confusion_matrix(perc_pretrained, fram_2common_X_val.to_numpy(), fram_y_val['TenYearCHD'], \n",
    "                        cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "# Save figure\n",
    "plt.savefig(\"Frammingham_Perceptron_confusion_matrix_pre-training.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a lower regularization parameter to allow SVM learn faster with the second dataset\n",
    "svm_pretrained.alpha = 0.005 # Low C, means need of more support vectors (here we have more data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial fit just iterate once through the training set, so 10 times with Cross Validation are performed\n",
    "\n",
    "# Steno iterations \n",
    "steno_folds = 10\n",
    "\n",
    "# Steno repetitions \n",
    "steno_repetitions = 1 \n",
    "\n",
    "# Declare a StratifiedKFold object with 10 folds\n",
    "skf = StratifiedKFold(n_splits = steno_folds, shuffle = True, random_state = 12345)\n",
    "\n",
    "# For simplicity of code\n",
    "X = steno_2common_X_train.to_numpy()\n",
    "y = np.ravel(steno_y_train['Class_label_binary'])\n",
    "\n",
    "# Dummy counter\n",
    "i = 0\n",
    "\n",
    "# Empty list to store the results of the 10 iterations\n",
    "steno_perc_train_results = []\n",
    "steno_svm_train_results = []\n",
    "\n",
    "# Current model \n",
    "curr_perc_model = perc_pretrained\n",
    "curr_svm_model = svm_pretrained\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "    # Extract the training and test set for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the model for this fold\n",
    "    perc_posttrained = curr_perc_model.partial_fit(X_train, y_train, classes=np.unique(steno_y_train['Class_label_binary']))\n",
    "    svm_posttrained = curr_svm_model.partial_fit(X_train, y_train, classes=np.unique(steno_y_train['Class_label_binary']))\n",
    "\n",
    "    # Predict the test set\n",
    "    y_perc_pred = perc_posttrained.predict(X_test)\n",
    "    y_svm_pred = svm_posttrained.predict(X_test)\n",
    "\n",
    "    # Test the model for this fold \n",
    "    perc_auc = metrics.roc_auc_score(y_test, y_perc_pred)\n",
    "    svm_auc = metrics.roc_auc_score(y_test, y_svm_pred)\n",
    "\n",
    "\n",
    "    # Print the results for this fold\n",
    "    print(\"Perceptron: Steno Classification (5 common) - Fold %i: %.2f\" % (i, perc_auc))\n",
    "    print(\"SVM: Steno Classification (5 common) - Fold %i: %.2f\" % (i, svm_auc))\n",
    "\n",
    "    print(\"Perceptron coefficients: \", perc_posttrained.coef_)\n",
    "    print(\"SVM coefficients: \", svm_posttrained.coef_) \n",
    "\n",
    "    # Append the results to the list\n",
    "    steno_perc_train_results.append(perc_auc)\n",
    "    steno_svm_train_results.append(svm_auc)\n",
    "\n",
    "    # Update current model \n",
    "    curr_perc_model = perc_posttrained\n",
    "\n",
    "# Plot auc vs iteration with perceptron\n",
    "plt.figure()\n",
    "plt.plot(range(steno_folds*steno_repetitions), steno_perc_train_results)\n",
    "\n",
    "# Set title and labels\n",
    "plt.title(\"Perceptron: Steno Classification (5 common) - AUC vs. Iteration\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"AUC\")\n",
    "\n",
    "# Plot auc vs iteration with SVM\n",
    "plt.plot(range(steno_folds*steno_repetitions), steno_svm_train_results)\n",
    "\n",
    "# Set legend \n",
    "plt.legend([\"Perceptron\", \"SVM\"])\n",
    "\n",
    "# Set title and labels \n",
    "plt.title(\"SVM: Steno Classification (5 common) - AUC vs. Iteration\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"AUC\")\n",
    "\n",
    "# Save figure \n",
    "plt.savefig(\"Steno Classification (5 common) - AUC vs. Iteration.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation after incremental training (SVM)\n",
    "steno_acc_SVM_post, steno_auc_SVM_post, f1_steno_SVM_post, recall_steno_SVM_post, prec_steno_SVM_post = perc_clas_eval(svm_posttrained, steno_2common_X_val.to_numpy(), steno_y_val['Class_label_binary'])\n",
    "print(\"SVM - Steno Only 5 common -> ACC: %f || AUC: %f || F1-score: %f || Recall: %f || Precision: %f\" % (steno_acc_SVM_post, steno_auc_SVM_post, f1_steno_SVM_post, recall_steno_SVM_post, prec_steno_SVM_post))\n",
    "fram_acc_SVM_post, fram_auc_SVM_post, f1_fram_SVM_post, recall_fram_SVM_post, prec_fram_SVM_post = perc_clas_eval(svm_posttrained, fram_2common_X_val.to_numpy(), fram_y_val['TenYearCHD'])\n",
    "print(\"SVM - Frammingham Only 5 common -> ACC: %f || AUC: %f || F1-score: %f || Recall: %f || Precision: %f\" % (fram_acc_SVM_post, fram_auc_SVM_post, f1_fram_SVM_post, recall_fram_SVM_post, prec_fram_SVM_post))\n",
    "\n",
    "# Save results in an Excel file \n",
    "results = pd.DataFrame({'ACC': [steno_acc_SVM_post, fram_acc_SVM_post], 'AUC': [steno_auc_SVM_post, fram_auc_SVM_post], 'F1': [f1_steno_SVM_post, f1_fram_SVM_post], 'Recall': [recall_steno_SVM_post, recall_fram_SVM_post], 'Precision': [prec_steno_SVM_post, prec_fram_SVM_post]}, index=['Steno Only 5 common', 'Frammingham Only 5 common'])\n",
    "results.to_excel('SVM_post_training_Steno_Frammingham_5common.xlsx')\n",
    "\n",
    "\n",
    "# Model validation after incremental training (Perceptron)\n",
    "steno_acc_perc_post, steno_auc_perc_post, f1_steno_perc_post, recall_steno_perc_post, prec_steno_perc_post = perc_clas_eval(perc_posttrained, steno_2common_X_val.to_numpy(), steno_y_val['Class_label_binary'])\n",
    "print(\"Perceptron After Incr. training - Steno Only 5 common -> ACC: %f || AUC: %f || F1-score: %f || Recall: %f || Precision: %f\" % (steno_acc_perc_post, steno_auc_perc_post, f1_steno_perc_post,  recall_steno_perc_post, prec_steno_perc_post))\n",
    "fram_acc_perc_post, fram_auc_perc_post, f1_fram_perc_post, recall_fram_perc_post, prec_fram_perc_post = perc_clas_eval(perc_posttrained, fram_2common_X_val.to_numpy(), fram_y_val['TenYearCHD'])\n",
    "print(\"Perceptron After Incr. training - Frammingham Only 5 common -> ACC: %f || AUC: %f || F1-score: %f || Recall: %f || Precision: %f\" % (fram_acc_perc_post, fram_auc_perc_post, f1_fram_perc_post, recall_fram_perc_post, prec_fram_perc_post))\n",
    "\n",
    "# Save results in an Excel file\n",
    "results = pd.DataFrame({'ACC': [steno_acc_perc_post, fram_acc_perc_post], 'AUC': [steno_auc_perc_post, fram_auc_perc_post], 'F1': [f1_steno_perc_post, f1_fram_perc_post], 'Recall': [recall_steno_perc_post, recall_fram_perc_post], 'Precision': [prec_steno_perc_post, prec_fram_perc_post]}, index=['Steno Only 5 common', 'Frammingham Only 5 common'])\n",
    "results.to_excel('Perceptron_post_training_Steno_Frammingham_5common.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix in the pre-training\n",
    "title = \"Steno Classification Approach (Steno post-training) - SVM \"\n",
    "disp = plot_confusion_matrix(svm_posttrained, steno_2common_X_val, steno_y_val['Class_label_binary'],\n",
    "                        cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "# Save figure\n",
    "plt.savefig(\"Steno_SVM_post_training.png\", dpi = 300)\n",
    "\n",
    "title = \"Frammingham Classification Approach (Steno post-training) - SVM\"\n",
    "disp = plot_confusion_matrix(svm_posttrained, fram_2common_X_val.to_numpy(), fram_y_val['TenYearCHD'], \n",
    "                        cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "# Save figure\n",
    "plt.savefig(\"Frammingham_SVM_post_training.png\", dpi = 300)\n",
    "\n",
    "# Confusion matrix for Frammingham \n",
    "title = \"Steno Classification Approach (Steno post-training) - Perceptron\"\n",
    "disp = plot_confusion_matrix(perc_posttrained, steno_2common_X_val, steno_y_val['Class_label_binary'],\n",
    "                        cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "# Save figure\n",
    "plt.savefig(\"Steno_Perceptron_post_training.png\", dpi = 300)\n",
    "\n",
    "title = \"Frammingham Classification Approach (Steno post-training) - Perceptron\"\n",
    "disp = plot_confusion_matrix(perc_posttrained, fram_2common_X_val.to_numpy(), fram_y_val['TenYearCHD'], \n",
    "                        cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "# Save figure \n",
    "plt.savefig(\"Frammingham_Perceptron_post_training.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataframe with SVM pre and post \n",
    "results = pd.DataFrame({'ACC - Prev': [steno_acc_SVM_prev, fram_acc_SVM_prev],\n",
    "                        'ACC - Post': [steno_acc_SVM_post, fram_acc_SVM_post],\n",
    "                        'AUC - Prev': [steno_auc_SVM_prev, fram_auc_SVM_prev], \n",
    "                        'AUC - Post': [steno_auc_SVM_post, fram_auc_SVM_post],\n",
    "                        'F1 - Prev': [f1_steno_SVM_prev, f1_fram_SVM_prev],\n",
    "                        'F1 - Post': [f1_steno_SVM_post, f1_fram_SVM_post],\n",
    "                        'Recall - Prev': [recall_steno_SVM_prev, recall_fram_SVM_prev],\n",
    "                        'Recall - Post': [recall_steno_SVM_post, recall_fram_SVM_post],\n",
    "                        'Precision - Prev': [prec_steno_SVM_prev, prec_fram_SVM_prev],\n",
    "                        'Precision - Post': [prec_steno_SVM_post, prec_fram_SVM_post]}, index=['Steno Only 5 common - SVM', 'Frammingham Only 5 common - SVM'])\n",
    "results.to_excel('SVM_Steno_Frammingham_5common.xlsx')\n",
    "\n",
    "# Create a Dataframe with Perceptron pre and post\n",
    "results = pd.DataFrame({'ACC - Prev': [steno_acc_perc_prev, fram_acc_perc_prev],\n",
    "                        'ACC - Post': [steno_acc_perc_post, fram_acc_perc_post],\n",
    "                        'AUC - Prev': [steno_auc_perc_prev, fram_auc_perc_prev],\n",
    "                        'AUC - Post': [steno_auc_perc_post, fram_auc_perc_post],\n",
    "                        'F1 - Prev': [f1_steno_perc_prev, f1_fram_perc_prev],\n",
    "                        'F1 - Post': [f1_steno_perc_post, f1_fram_perc_post],\n",
    "                        'Recall - Prev': [recall_steno_perc_prev, recall_fram_perc_prev],\n",
    "                        'Recall - Post': [recall_steno_perc_post, recall_fram_perc_post],\n",
    "                        'Precision - Prev': [prec_steno_perc_prev, prec_fram_perc_prev],\n",
    "                        'Precision - Post': [prec_steno_perc_post, prec_fram_perc_post]}, index=['Steno Only 5 common - Perceptron', 'Frammingham Only 5 common - Perceptron'])\n",
    "results.to_excel('Perceptron_Steno_Frammingham_5common.xlsx')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenated steno and framingham validation set \n",
    "X_val = pd.concat([steno_2common_X_val, fram_2common_X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution time \n",
    "n_instances = X_test.shape[0]\n",
    "SVM_runtimes = np.zeros(n_instances, dtype=float)\n",
    "for i in range(n_instances):\n",
    "    instance = X_test[[i], :]\n",
    "    start = time.time()\n",
    "    svm_posttrained.predict(instance)\n",
    "    SVM_runtimes[i] = time.time() - start\n",
    "\n",
    "MLP_runtimes = np.zeros(n_instances, dtype=float)\n",
    "for i in range(n_instances):\n",
    "    instance = X_test[[i], :]\n",
    "    start = time.time()\n",
    "    perc_posttrained.predict(instance)\n",
    "    MLP_runtimes[i] = time.time() - start\n",
    "\n",
    "print(SVM_runtimes.mean())\n",
    "print(SVM_runtimes.std())\n",
    "print(MLP_runtimes.mean())\n",
    "print(MLP_runtimes.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export SVM and Perceptron using pickle\n",
    "pickle.dump(svm_posttrained, open('svm_posttrained.sav', 'wb'))\n",
    "pickle.dump(perc_posttrained, open('perc_posttrained.sav', 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk_calculators",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e13a11719942d84b21bb41b4f5636b1eb742aff7475cbe900d1d93a5317ed696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
